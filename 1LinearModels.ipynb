{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Linear models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Supervised learning (briefly)\n",
    "* Perceptron (briefly)\n",
    "* Linear Regression\n",
    "    * Hypothesis set\n",
    "    * Error function\n",
    "    * Formula for $w^\\ast$\n",
    "* Logistic Regression\n",
    "    * Hypothesis set\n",
    "    * Sigmoid function\n",
    "    * Error function\n",
    "    * Gradient descent\n",
    "    * Softmax "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised learning\n",
    "\n",
    "In the Supervised Learning setting we are given a dataset $D = \\{(x_1,y_1),...,(x_n,y_n)\\}$ to learn from. The way we \"learn\" is by using D to search a hypothesis space H for some \"best\" hypothesis $g\\in H$. By \"best\", we mean that we want g to be as close to the __ unknown target function f__ as possible, i.e.: \n",
    "\n",
    "$$ g \\approx f $$\n",
    "\n",
    "We most often find g by minimizing an in-sample error function $E_{in}(h)$. \"Learning\" is the process of finding g, and when we have found it, we can use it to predict on new inputs.\n",
    "\n",
    "Within supervised learning we distinguish between two subcategories. If the output y is a real number we call it __regression__. If the output y is a member of a discrete set - e.g. $y \\in \\{red,blue,green\\}$ - then we call it __classification__.\n",
    "\n",
    "In Supervised Learning we try to minimize $E_{in}(g)$, but what we _really_ care about in the end is having a low out-of-sample error $E_{out}(g)$, that is, we only care about how g performs on _new_ data. Since we cannot measure $E_{out}$ during training, we must try to make g __generalize__ well, such that it performs well on new data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron\n",
    "The perceptron is the simplest of linear models. It is a binary __classification__ model ({-1,+1}), and the hypothesis set looks a follows:\n",
    "\n",
    "$$ H=\\{h(x)=\\text{sign}(w^T x) \\mid w\\in \\mathbb{R}^{d+1}\\}$$\n",
    "\n",
    "The __Perceptron Learning Algorithm(PLA)__ search for a hyperplane which separate all datapoints correctly. While a misclassified point x exists, the algorithm will update the hypothesis, effectively moving the hyperplane in the direction of correctly classifying x. The algorithm never terminates if the data is not linearly separable, but if the data is linearly separable, it is guaranteed to pick a $g\\in H$ with $E_{in} = 0$. \n",
    "\n",
    "The error function we wish to minimize is:\n",
    "\n",
    "$$E_{in}(h)=\\frac{1}{N}\\sum_{i=1}^N \\mathbb{1}_{h(x_i)\\neq y_i} $$\n",
    "\n",
    "Where $\\mathbb{1}_{h(x_i)\\neq y_i} = 1$ if h misclassifies $x_i$, and 0 if not.  \n",
    "\n",
    "With a simple augmentation, the PLA can be used on non linearly separable datasets. The idea is to keep the currently best h \"in a pocket\", while runing for i iterations(instead of until $E_{in} =0$). After the i iterations, the algorithm stops and returns the stored hypothesis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
