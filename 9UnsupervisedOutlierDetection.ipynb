{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9) Unsupervised learning - Outlier detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Unsupervised learning (briefly)\n",
    "* Outlier detection\n",
    "* Dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised learning\n",
    "\n",
    "In unsupervised learning the training data has the form $D = \\{(x_1, ?), (x_2, ?),...(x_n, ?)\\}$. So we have no labels for the data pwoints, and the goal is to get an insigt into the data distribution, and see if we can make some sense of it. __Three important problems__ are __clustering__, where we applying algorithms to try and find natural clusters within the data, and __outlier detection__, where we try to indentity data points which seem to deviate from the pattern in the data, and finally __dimensionality reduction__ where we seek to reduce the dimensionality of our data while preserving as much information as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier detection\n",
    "\n",
    "The standard definition of an __outlier__ is that is an object that deviates so much from the rest of the data set as to\n",
    "arouse suspicion that it was generated by a different mechanism. It could be that the point is just an error, and so we might want to remove it. It could also indicate fraud, or simply be a valid but rare point. An outlier can be both an abnomality or simply just noise. Often the abnormalies can have high interest to the analyst.\n",
    "\n",
    "Outlier detection can be applied to areas such as:\n",
    "\n",
    "- Credit card fraud detection\n",
    "- Telecom fraud detection \n",
    "- Customer segmentation\n",
    "- Medical analysis\n",
    "- Surveillance\n",
    "\n",
    "The output of an outlier algorithm can be binary labels, or a score for how much an object is an outlier. \n",
    "\n",
    "#### Basic outlier detection models\n",
    "\n",
    "\n",
    "\n",
    "#### Probabilistic and  statistical approach\n",
    "\n",
    "Often first step before smarter things.\n",
    "\n",
    "Limitations: Only for single features. Sensitive to many outliers, because outliers affect learning. Not all outliers are detected\n",
    "\n",
    "#### Expectation maximization\n",
    "\n",
    "#### Density based clustering for outlier detection\n",
    "\n",
    "FOr dbscan. All objects not in cluster are outliers\n",
    "\n",
    "\n",
    "### Local outliers instead of global outliers\n",
    "\n",
    "Each object has an outlier factor: degree to which the object deviates. \n",
    "\n",
    "k-distance of an object p:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality reduction\n",
    "\n",
    "The goal of dimensionality reduction is to take high dimensional data, and reduce the number of dimensions while preserving most of the information/structure in the data. High dimensional data can cause overfitting, and also increase the computational cost. Reducing to two dimensions is often used to facilitate visualization of higher dimensional data.\n",
    "\n",
    "__Principle Component Analysis (PCA)__, is a well known technique for reducing the number of dimensions.\n",
    "\n",
    "SOME ELEMENTS CHANGE TOGETHER\n",
    "\n",
    "#### Principle component analysis\n",
    "\n",
    "Preprocessing data?\n",
    "\n",
    "\n",
    "#### Covariance geometric intuition\n",
    "\n",
    "http://www.visiondummy.com/2014/04/geometric-interpretation-covariance-matrix/\n",
    "\n",
    "\n",
    "<img src=\"imgs/covintuition.png\" style=\"width: 450px;\"/>\n",
    "\n",
    "\"As we see in the figure the covariance matrix defines both the spread (variance), and the orientation (covariance) of our data. So, if we would like to represent the covariance matrix with a vector and its magnitude, we should simply try to find the vector that points into the direction of the largest spread of the data, and whose magnitude equals the spread (variance) in this direction\"\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
