{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Decision Trees & Ensemble Methods\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Supervised learning (briefly)\n",
    "* Decision trees\n",
    "    * Learning theory for decision trees\n",
    "    * Classification \n",
    "    * Regression\n",
    "* Ensemble methods\n",
    "    * Bootstrap aggregating (bagging)\n",
    "    * (boosting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised learning\n",
    "\n",
    "In the Supervised Learning setting we are given a dataset $D = \\{(x_1,y_1),...,(x_n,y_n)\\}$ to learn from. The way we \"learn\" is by using D to search a hypothesis space H for some \"best\" hypothesis $g\\in H$. By \"best\", we mean that we want g to be as close to the __ unknown target function f__ as possible, i.e.: \n",
    "\n",
    "$$g \\approx f$$\n",
    "\n",
    "We most often find g by minimizing an in-sample error function $E_{in}(h)$. The process of finding g is what we call \"training\" and when we have found it, we can use it to predict on new inputs.\n",
    "\n",
    "Within supervised learning we distinguish between __two subcategories__. If the output y is a real number we call it __regression__. If the output y is a member of a discrete set - e.g. $y \\in \\{red,blue,green\\}$ - then we call it __classification__.\n",
    "\n",
    "In Supervised Learning we try to minimize $E_{in}(g)$, but what we _really_ care about in the end is having a low out-of-sample error $E_{out}(g)$, that is, in the end we only care about how g performs on _new_ data. Since we cannot measure $E_{out}(g)$ during training, we hope that we can generalize such that $E_{in}(g)$ - which we _can_ measure - is close to $E_{out}(g)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision trees\n",
    "\n",
    "A decision trees represent sequences of simple rules that we can follow from root to leaf and end up with a conclusion. For the tree below we first ask about the age specified by the input point, then we follow the path to the next node and ask the next question. This continues until we are at a leaf at which point the output/conclusion is either \"healty\" or \"alcoholic\". This specific tree is a classification tree, but we can also have regression trees. The only difference between the two types is the output, and therefore the leaves.\n",
    "\n",
    "<img src=\"imgs/decisiontree.png\" style=\"width: 550px;\"/>\n",
    "\n",
    "Decision trees are \"white box\" models, in the sense that it is very easy to see why a given input produced a given output - you simply start at the root and use your datapoint to answer the questions until you end up at a leaf. This is in contrast to large neural networks, where it is much harder to argue why a given output was produced. \n",
    "\n",
    "A hypothesis splits the input into rectangles defined by the questions of the internal nodes. For the 2 dimensional example above, the region looks like this:\n",
    "\n",
    "<img src=\"imgs/decisiontreehypo.png\" style=\"width: 400px;\"/>\n",
    "\n",
    "Mathematically a hypothesis is defined as:\n",
    "\n",
    "$$h(x) = \\sum_{regions\\ r} 1_{x\\in r} c_r$$\n",
    "\n",
    "TODO: mere om disse konstanter c_r\n",
    "\n",
    "#### Learning theory for decision trees\n",
    "\n",
    "With a big enough tree we can fit anything perfectly, so the VC dimension of the decision tree is infinite. This means we have to restrict ourselves when building the tree to avoid overfitting. We do this by trying to keep the trees small/simple. We can do this with regularization, resulting in a fixed depth tree. Or we can build the full tree and then prune it to a fix size using validation. \n",
    "\n",
    "Since the hypothesis set is complex, the bias is low. The variance, on the other hand, is high. A new dataset might result in a completely different tree. To reduce the variance we can use bootstrap aggregation (bagging).\n",
    "\n",
    "#### Classification\n",
    "\n",
    "We can build a classification tree by following a recursive procedure. First pick a question to ask, then split D according to how the data points answer the question. Recurse on the new nodes. We stop when all questions are asked down the path, or the remaining data points left in the partition have the same class. When we stop the recursion we have a new leaf, and the leaf should be labeled with the majority of the class labels left in the partition.\n",
    "\n",
    "We would like the tree to be small and general to prevent overfitting. So how do we pick the best questions to ask?  __we want to ask questions that provide the most information gain__. We can do this greedy by picking the questions which is the best question _right now_, i.e. the question that minimize the 0/1 loss error on the new tree.\n",
    "\n",
    "A better way is to pick the question that __minimize entropy__ in children.\n",
    "\n",
    "Entropy is a measure of uncertainty. For a given current subset of D, let $p_k$ be the number of elements of class k divided by the total number of elements in the subset. \n",
    "\n",
    "Entropy is then defined as: \n",
    "\n",
    "$$ -\\sum_k p_k log_2(pk)$$\n",
    "\n",
    "__The best split is the one that gives us the most information gain, we can compute that for each attribute using entropy__.\n",
    "\n",
    "TODO: forklar\n",
    "\n",
    "#### Regression \n",
    "\n",
    "Regression trees can be build in the same greedy approach as for classification trees. Pick the question that minimize the least squared error on the next level.\n",
    "\n",
    "When we stop the recursion we have a new leaf, and the leaf should be labeled with the mean because it minimize the least squares error.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble methods\n",
    "\n",
    "#### Bootstrap aggregation (bagging)\n",
    "\n",
    "Bagging is a technique to __reduce variance__. It is applicable to other learning models, but is often used with decision trees. Using decision trees we are in a low bias, high variance scenario, so reducing the variance by averaging over many trained models seem like a good idea.\n",
    "\n",
    "<img src=\"imgs/biasvariancebullet.png\" style=\"width: 400px;\"/>\n",
    "\n",
    "The problem is that we only have one dataset D, and splitting this up into many smaller data sets is a bad idea. Instead we create new data sets where the data points are sampled uniformly (with replacement) from D (__bootstrap samples__). These new data sets are then used as \"independent\" (even though they are not) data sets, and are each used to build separate tree, i.e. create final hypotheses $g_i$. __This \"ensemble\" can the be used to predict on a new data point. For classification, the majority vote is returned as the final prediction, and for regression the mean of the predictions is returned.__\n",
    "\n",
    "__Random Forest__ is \"bagging with a twist\" to decorrelate trees. \n",
    "\n",
    "The idea in random forests is to improve the variance reduction of bagging by reducing the correlation between trees, without increasing the variance too much. This is achieved in the tree-growing process through random selection of the input variables.\n",
    "\n",
    "\n",
    "\n",
    "#### Boosting\n",
    "\n",
    "Boosting is a technique to __reduce bias__. Boosting combines many \"weak\" classifiers into a powerful ensemble/commitee. A weak classifier is one whose error rate is slightly better than random guessing. The weak classifiers are produced by sequentially training a new classifier on modified versions of the data set. \n",
    "\n",
    "The hope is that each unit in the committee does well on a certain part of the input space. Training on different modified versions of the data set enforce this behavior. The idea here is to pick functions that add value to areas where the current hypothesis fails. \n",
    "\n",
    "For a binary classification setting with $y \\in \\{-1,1\\}$, and weak classifiers $g_i,...,g_M$, the final prediction is given by:\n",
    "\n",
    "$$ G(x) =  sign\\big(\\sum_{i=1}^M \\alpha_i g_i(x)\\big)$$\n",
    "\n",
    "So each $\\alpha_i$ is a measure of the importance of the corresponding weak classifier. __Since each point now has a weight associated with it, the weak learner must be able to accept a weighted collection of data points.__\n",
    "\n",
    "\n",
    "#### Adaboost algorithm\n",
    "\n",
    "The adaptive boosing algorithm looks as follows:\n",
    "\n",
    "<img src=\"imgs/adaboosting.png\" style=\"width: 600px;\"/>\n",
    "\n",
    "The function for computing the quality of the classifiers $\\alpha_m$ is shown below:\n",
    "\n",
    "<img src=\"imgs/qualityfuncada.png\" style=\"width: 300px;\"/>\n",
    "\n",
    "We can see that, as the error of the classifier goes down, the quality measure $\\alpha_m$ goes up. The result is that this classifier has higher impact on the final prediction $G(x)$.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
